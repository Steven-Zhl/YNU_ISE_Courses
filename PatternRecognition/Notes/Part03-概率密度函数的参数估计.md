# Part03-概率密度函数的参数估计

> 贝叶斯决策理论理论上是最优的，前提是需要准确知晓各先验概率$P(\omega_i)$和类条件概率密度$p(X|\oemga_i)&，但实际中往往不知道这些概率。
>
> 但我们总得知道点信息吧，比如样本服从什么分布。在知道服从什么分布之后，任务就是根据这种分布的概率密度和样本估计参数。
>
> 当然，也有可能不知道样本服从什么分布，这时候就需要用到其他方法。这就是本章的另一部分内容。

# 3.0 Pre

## 3.0.1 目录

* [Part03-概率密度函数的参数估计](#part03-概率密度函数的参数估计)
* [3.0 Pre](#30-pre)
  * [3.0.1 目录](#301-目录)
  * [3.0.2 概念汇总](#302-概念汇总)
  * [3.0.3 重点](#303-重点)
  * [3.0.4 基础知识](#304-基础知识)
    * [(1) (一维)正态分布的概率密度函数](#1-一维正态分布的概率密度函数)
* [3.1 概率密度函数估计概论](#31-概率密度函数估计概论)
* [3.2 最大似然估计](#32-最大似然估计)
  * [3.2.1 符号说明](#321-符号说明)
  * [3.2.2 似然函数](#322-似然函数)
  * [3.2.3 最大似然估计](#323-最大似然估计)
* [Ques03-例题整理](#ques03-例题整理)
  * [\[计算题·最大似然估计(以一维正态分布为例)\]](#计算题最大似然估计以一维正态分布为例)

## 3.0.2 概念汇总

* [参数估计](#31-概率密度函数估计概论)
  * [最大似然估计](#32-最大似然估计)

## 3.0.3 重点

## 3.0.4 基础知识

### (1) (一维)正态分布的概率密度函数

> 这章只是以正态分布举例，并不与正态分布直接相关，但作为一个基础知识，认为你本就该知道。

* $p(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
  * $\mu$：均值
  * $\sigma$：标准差

# 3.1 概率密度函数估计概论

* 本章所说的**概率密度函数估计**指的是**估计类条件概率密度函数**。大多数时候处理的都是参数估计，非参数估计较少。

> **参数估计**：已知样本$X$的类条件概率密度函数$p(X|\omega_i)$服从某种分布，但分布的参数未知，现在需要用一些方法将这些分布参数计算出来。只有当什么都不知道的时候，才会用非参数估计。
>> 常用方法为**最大似然估计**和**贝叶斯估计**，此外本章还讲解了**贝叶斯学习**方法。
>
> **非参数估计**：不知道样本$X$的分布形式，直接估计类条件概率密度函数$p(X|\omega_i)$。
>> 常用方法为$Parzen窗法$和$k_N-近邻法$。

# 3.2 最大似然估计

## 3.2.1 符号说明

* $\omega_i$：类别，共有$c$类
* $p(X|\omega_i)$：概率密度函数
* $\theta_i$：表征该函数的参数
* $\hat{\theta}$：参数的估计值
* $H(\theta)$：对数似然函数，就是传统似然函数外面套了个$ln()$

## 3.2.2 似然函数

> **似然函数**是一个关于参数$\theta$的函数，通常表示为$L(\theta|X)$，它的值反映了在已知参数$\theta$的条件下，观测到样本$X$的概率。

* 假设从$\omega_i$中抽取$N$个样本组成一个样本集$X^{(N)}$，则这$N$个样本的联合概率密度函数$p(X^{(N)},\theta)$为相对于样本集$X^{(N)}$的$\theta$的似然函数。

* $L(\theta|X^{(N)})=p(X^{(N)}|\theta)=p(X_1,X_2,...,X_N|\theta)$
  * 当$X_1,X_2,...,X_N$相互独立抽取时，可进一步写为$\Pi^N_{k=1}p(X_k|\theta)$

## 3.2.3 最大似然估计

* 注意到上述似然函数是连续可导函数，根据之前的高数知识，可知当$\frac{dp(X^{(N)}|\theta)}{d\theta}=0$时，似然函数取得最大值。
* 由于对数函数具有单调性，为了便于分析，对似然函数套个$ln$，得到对数似然函数：
  * (之所以需要取对数这一步，是因为取了对数计算更简单，且最优解与原问题的最优解相同。)
  * $H(\theta)=ln p(X^{(N)}|\theta)$
  * 又因为$p(X^{(N)}|\theta)=\Pi^N_{k=1}p(X_k|\theta)$，取了对数之后，连乘就变成了累加，这是能显著降低计算难度的。
  * 显然，当估计参数$\hat{\theta}$使得对数似然函数取得最大值时，似然函数也达到最大值。即最大似然估计与$\frac{dH(\theta)}{d\theta}=0$的解等价。

# Ques03-例题整理

## [计算题·最大似然估计(以一维正态分布为例)]

> 题目内容

* 设从$\omega_i$中抽取了$N$个样本，这$N$个样本是从一维正态分布概率密度函数$p(X|\omega_i)$总体中独立抽取的，用最大似然估计方法，估计正态分布均值和协方差。

> 分析与解答

* 这个题就是个模板题：并不难，但是它展现了这类题的标准解题步骤。
* 首先摆公式：$p(X^{(N)}|\theta)=\Pi^N_{k=1}p(X_k|\theta)$（因为说了，$N$个样本是独立抽取的）
  * $\theta_1=\mu,\theta_2=\sigma^2$，也就是把需要估计的参数直接认为是$\sigma$的各维(求啥设啥，这很合理)。
* 然后根据先验知识（在这门课之前就已知的知识），正态分布的概率密度函数为$p(X_k|\theta)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(X_k-\mu)^2}{2\sigma^2}}$。
* 根据[最大似然估计](#323-最大似然估计)的套路，对似然函数取对数，得到对数似然函数：
  * $ln p(X_k|\theta)=-\frac{1}{2}ln(2\pi \sigma^2)-\frac{(X_k-\mu)^2}{2\sigma^2}$
* 再根据高数时的套路，令偏导为0，取得极值点，即为最(大)值点
  * $$\begin{cases}
        \sum^N_{k=1}\frac{d}{d\theta_1}ln p(X_k|\theta)=\sum^N_{k=1}\frac{X_k-\theta_1}{\theta_2}=0\\
        \sum^N_{k=1}\frac{d}{d\theta_2}lnp(X_k|\theta)=\sum^N_{k=1}(-\frac{1}{2\theta_2}+\frac{(X_k-\theta_1)^2}{2\theta_2^2})=0
    \end{cases}$$
* 由以上方程组解得均值和方差的估计量为
  * $\hat{\mu}=\hat{\theta_1}=\frac{1}{N}\sum^N_{k=1}X_k$
  * $\hat{\sigma^2}=\hat{\theta_2}=\frac{1}{N}\sum^N_{k=1}(X_k-\hat{\mu})^2$
* 对于一般的多维正态分布，用同样的方法可以得出其最大似然估计为：
  * $\hat{\mu_i}=\frac{1}{N}\sum^N_{k=1}X_k$
  * $\hat{\Sigma_i}=\frac{1}{N}\sum^N_{k=1}(X_k-\hat{\mu_i})(X_k-\hat{\mu_i})^T$
* > 可以看出，使用最大似然估计得出的均值和方差与概率论中的计算结果完全一致。
